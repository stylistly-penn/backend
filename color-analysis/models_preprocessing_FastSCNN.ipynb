{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ulxDNcSNOq9",
        "outputId": "c05c5d1c-2d9b-4f25-99ab-c7ae4ec68c48"
      },
      "outputs": [],
      "source": [
        "# === colab configuration ===\n",
        "# p.s. when training on colab, weights are saved on Drive (directory DSCAS/weights).\n",
        "# p.p.s. skip this cell if running demo file locally!\n",
        "\n",
        "! pip install torch-summary\n",
        "! pip install ray\n",
        "! pip install tensorboardX==2.5.1\n",
        "! pip install tensorboard==2.11.2\n",
        "from google.colab import drive, files\n",
        "import sys\n",
        "\n",
        "# setting paths\n",
        "repository_path = '/content/deep-seasonal-color-analysis-system/'\n",
        "dataset_path = repository_path + 'headsegmentation_dataset_ccncsa/'\n",
        "dataset_path_drive = '/content/drive/MyDrive/DSCAS/headsegmentation_dataset_ccncsa/'\n",
        "weights_path = repository_path + 'models/weights/'\n",
        "weights_path_drive = '/content/drive/MyDrive/DSCAS/weights/'\n",
        "checkpoint_path = repository_path + 'models/preprocessing/'\n",
        "checkpoint_archive = '/content/' + checkpoint_path.split('/')[-2] + '.zip'\n",
        "\n",
        "sys.path.insert(0, repository_path)\n",
        "\n",
        "# cloning project repository and downloading dataset\n",
        "drive.mount('/content/drive')\n",
        "! test ! -d $repository_path && git clone https://github.com/mrcmich/deep-seasonal-color-analysis-system.git\n",
        "! test ! -d $dataset_path && cp -R $dataset_path_drive $dataset_path\n",
        "%cd $repository_path\n",
        "\n",
        "# setting branch and pulling updates\n",
        "branch = 'main'\n",
        "! git checkout $branch\n",
        "! git pull origin $branch\n",
        "\n",
        "executing_on_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PUNWSumyhhyN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision.transforms as T\n",
        "from sklearn.model_selection import train_test_split\n",
        "from models import dataset, training_and_testing\n",
        "from models.local.FastSCNN.models import fast_scnn\n",
        "from metrics_and_losses import metrics\n",
        "from utils import segmentation_labels, custom_transforms, model_names\n",
        "from models import config\n",
        "from slurm_scripts import slurm_config\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from functools import partial\n",
        "\n",
        "try:\n",
        "  executing_on_colab\n",
        "except NameError:\n",
        "  executing_on_colab = False\n",
        "  weights_path = config.WEIGHTS_PATH\n",
        "  dataset_path = config.DATASET_PATH\n",
        "  checkpoint_path = config.PREPROCESSING_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pSBN1RIFhhyP"
      },
      "outputs": [],
      "source": [
        "# === defining transforms ===\n",
        "\n",
        "diameter = 7\n",
        "sigma_color = 50\n",
        "sigma_space = 100\n",
        "horizontal_flip = custom_transforms.PartiallyDeterministicHorizontalFlip(p=0.5)\n",
        "center_crop = custom_transforms.PartiallyDeterministicCenterCrop(p=0.5)\n",
        "\n",
        "image_transform = T.Compose([\n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO), \n",
        "    custom_transforms.BilateralFilter(sigma_color, sigma_space, diameter), \n",
        "    T.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)])\n",
        "\n",
        "target_transform = T.Compose([T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO)])\n",
        "\n",
        "# fetching dataset\n",
        "n_classes = len(segmentation_labels.labels)\n",
        "img_paths, label_paths = dataset.get_paths(dataset_path, file_name=config.DATASET_INDEX_NAME)\n",
        "X_train, _, Y_train, _ = train_test_split(img_paths, label_paths, test_size=0.20, random_state=99, shuffle=True)\n",
        "train_dataset = dataset.CcncsaDataset(X_train, Y_train, image_transform, target_transform)\n",
        "\n",
        "# setting up hyperparameters for training\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "n_epochs = 10\n",
        "batch_size = 32\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "score_fn = metrics.batch_mIoU\n",
        "learning_rate = 0.01\n",
        "class_weights = torch.tensor(config.CLASS_WEIGHTS, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XFh0Gb1Dp_1k"
      },
      "outputs": [],
      "source": [
        "# model parameters\n",
        "model_name = \"fastscnn\"\n",
        "model = fast_scnn.FastSCNN(n_classes)\n",
        "optimizer = optim.Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ViTPkes9oxok"
      },
      "outputs": [],
      "source": [
        "# Ray Tune parameters\n",
        "cpus_per_trial = 0\n",
        "gpus_per_trial = torch.cuda.device_count()\n",
        "num_samples = 1  # Number of times each combination is sampled (n_epochs are done per sample)\n",
        "metric = \"val_loss\"\n",
        "metrics_columns = [\"train_loss\", \"train_score\", \"val_loss\", \"val_score\", \"training_iteration\"]\n",
        "local_dir = checkpoint_path + model_names.MODEL_NAMES[model_name]\n",
        "max_report_frequency = 600\n",
        "reporter = CLIReporter(\n",
        "    metric_columns=metrics_columns, max_report_frequency=max_report_frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9goVLwWZpJF",
        "outputId": "5ab94b93-8c07-44fa-8c56-9a38272d0604",
        "pycharm": {
          "is_executing": true
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_score</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  val_score</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_2cb75_00000</td><td>2023-02-03_01-26-46</td><td>True  </td><td>                </td><td>8ef2415d89094266b7e14dbf30798615</td><td style=\"text-align: right;\">               0</td><td>lenovo-notebook</td><td style=\"text-align: right;\">                        10</td><td>127.0.0.1</td><td style=\"text-align: right;\">12600</td><td style=\"text-align: right;\">             2684.44</td><td style=\"text-align: right;\">           260.923</td><td style=\"text-align: right;\">       2684.44</td><td style=\"text-align: right;\"> 1675384006</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">     0.13448</td><td style=\"text-align: right;\">     0.603462</td><td style=\"text-align: right;\">                  10</td><td>2cb75_00000</td><td style=\"text-align: right;\">  0.131481</td><td style=\"text-align: right;\">   0.618394</td><td style=\"text-align: right;\">   0.00500274</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-03 01:26:47,072\tINFO tune.py:762 -- Total run time: 2692.60 seconds (2692.33 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-02-03 01:26:46 (running for 00:44:52.34)\n",
            "Memory usage on this node: 6.2/7.4 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/1.34 GiB heap, 0.0/0.67 GiB objects\n",
            "Result logdir: c:\\Data\\GitHub\\deep-seasonal-color-analysis-system\\models\\preprocessing\\FastSCNN\\train_model_2023-02-03_00-41-54\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "| Trial name              | status     | loc             |   train_loss |   train_score |   val_loss |   val_score |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------|\n",
            "| train_model_2cb75_00000 | TERMINATED | 127.0.0.1:12600 |      0.13448 |      0.603462 |   0.131481 |    0.618394 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x13402d16740>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === training without augmentation ===\n",
        "\n",
        "checkpoint_dir = local_dir if executing_on_colab else (os.path.abspath('./' + local_dir) + '/')\n",
        "cfg = {\n",
        "    \"lr\": learning_rate,\n",
        "    \"lr_scheduler\": \"none\",\n",
        "    \"batch_size\": batch_size,\n",
        "    \"transform\": \"none\",\n",
        "    \"from_checkpoint\": False,\n",
        "    \"checkpoint_dir\": checkpoint_dir\n",
        "    }\n",
        "\n",
        "tune.run(partial(training_and_testing.train_model,\n",
        "                 device=device, model=model, dataset=train_dataset, n_epochs=n_epochs,\n",
        "                 score_fn=score_fn, loss_fn=loss_fn, optimizer=optimizer, num_workers=(0, 0),\n",
        "                 evaluate=True, class_weights=class_weights),\n",
        "         config=cfg,\n",
        "         num_samples=num_samples,\n",
        "         resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
        "         progress_reporter=reporter,\n",
        "         checkpoint_at_end=True,\n",
        "         checkpoint_freq=1,\n",
        "         local_dir=local_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downloading updated training results if running on colab\n",
        "! if test $executing_on_colab = 'True' ; then zip -r $checkpoint_archive $checkpoint_path ; fi\n",
        "if executing_on_colab is True: files.download(checkpoint_archive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W3OpWYa3ZpJF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_score</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  val_score</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_71c2f_00000</td><td>2023-02-03_02-14-55</td><td>True  </td><td>                </td><td>a255cb8b5e0d4d2b83b459b111b1b71d</td><td style=\"text-align: right;\">               0</td><td>lenovo-notebook</td><td style=\"text-align: right;\">                        10</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3468</td><td style=\"text-align: right;\">             2881.53</td><td style=\"text-align: right;\">           286.039</td><td style=\"text-align: right;\">       2881.53</td><td style=\"text-align: right;\"> 1675386895</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    0.124235</td><td style=\"text-align: right;\">     0.608309</td><td style=\"text-align: right;\">                  10</td><td>71c2f_00000</td><td style=\"text-align: right;\">  0.146889</td><td style=\"text-align: right;\">   0.606491</td><td style=\"text-align: right;\">      0.01946</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-03 02:14:55,941\tINFO tune.py:762 -- Total run time: 2888.65 seconds (2888.39 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-02-03 02:14:55 (running for 00:48:08.40)\n",
            "Memory usage on this node: 6.1/7.4 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/1.34 GiB heap, 0.0/0.67 GiB objects\n",
            "Result logdir: c:\\Data\\GitHub\\deep-seasonal-color-analysis-system\\models\\preprocessing\\FastSCNN\\train_model_2023-02-03_01-26-47\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "+-------------------------+------------+----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "| Trial name              | status     | loc            |   train_loss |   train_score |   val_loss |   val_score |   training_iteration |\n",
            "|-------------------------+------------+----------------+--------------+---------------+------------+-------------+----------------------|\n",
            "| train_model_71c2f_00000 | TERMINATED | 127.0.0.1:3468 |     0.124235 |      0.608309 |   0.146889 |    0.606491 |                   10 |\n",
            "+-------------------------+------------+----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x134033a9ea0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === training with augmentation: ColorJitter ===\n",
        "\n",
        "image_transform_with_augmentation = T.Compose([\n",
        "    T.ColorJitter(brightness=0.25, contrast=0.25), \n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO), \n",
        "    custom_transforms.BilateralFilter(sigma_color, sigma_space, diameter), \n",
        "    T.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)])\n",
        "\n",
        "train_dataset_with_augmentation = dataset.CcncsaDataset(\n",
        "    X_train, Y_train, image_transform_with_augmentation, target_transform)\n",
        "    \n",
        "model = fast_scnn.FastSCNN(n_classes)\n",
        "\n",
        "cfg[\"transform\"] = \"color_jitter\"\n",
        "\n",
        "tune.run(partial(training_and_testing.train_model,\n",
        "                 device=device, model=model, dataset=train_dataset_with_augmentation, n_epochs=n_epochs,\n",
        "                 score_fn=score_fn, loss_fn=loss_fn, optimizer=optimizer, num_workers=(0, 0),\n",
        "                 evaluate=True, class_weights=class_weights),\n",
        "         config=cfg,\n",
        "         num_samples=num_samples,\n",
        "         resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
        "         progress_reporter=reporter,\n",
        "         checkpoint_at_end=True,\n",
        "         checkpoint_freq=1,\n",
        "         local_dir=local_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downloading updated training results if running on colab\n",
        "! if test $executing_on_colab = 'True' ; then zip -r $checkpoint_archive $checkpoint_path ; fi\n",
        "if executing_on_colab is True: files.download(checkpoint_archive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AUA9IB-DZpJF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_score</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  val_score</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_2b9f4_00000</td><td>2023-02-03_03-00-57</td><td>True  </td><td>                </td><td>f4e057ca9f7e4fd5b42847a764b9ab8c</td><td style=\"text-align: right;\">               0</td><td>lenovo-notebook</td><td style=\"text-align: right;\">                        10</td><td>127.0.0.1</td><td style=\"text-align: right;\">12456</td><td style=\"text-align: right;\">             2753.36</td><td style=\"text-align: right;\">           275.702</td><td style=\"text-align: right;\">       2753.36</td><td style=\"text-align: right;\"> 1675389657</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    0.142049</td><td style=\"text-align: right;\">     0.589971</td><td style=\"text-align: right;\">                  10</td><td>2b9f4_00000</td><td style=\"text-align: right;\">  0.149761</td><td style=\"text-align: right;\">   0.600934</td><td style=\"text-align: right;\">   0.00784945</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-03 03:00:57,561\tINFO tune.py:762 -- Total run time: 2761.47 seconds (2761.19 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-02-03 03:00:57 (running for 00:46:01.21)\n",
            "Memory usage on this node: 6.2/7.4 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/1.34 GiB heap, 0.0/0.67 GiB objects\n",
            "Result logdir: c:\\Data\\GitHub\\deep-seasonal-color-analysis-system\\models\\preprocessing\\FastSCNN\\train_model_2023-02-03_02-14-56\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "| Trial name              | status     | loc             |   train_loss |   train_score |   val_loss |   val_score |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------|\n",
            "| train_model_2b9f4_00000 | TERMINATED | 127.0.0.1:12456 |     0.142049 |      0.589971 |   0.149761 |    0.600934 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x134033ab700>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === training with augmentation: horizontal_flip ===\n",
        "\n",
        "image_transform_with_augmentation = T.Compose([\n",
        "    horizontal_flip,\n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO), \n",
        "    custom_transforms.BilateralFilter(sigma_color, sigma_space, diameter), \n",
        "    T.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)])\n",
        "\n",
        "target_transform_with_augmentation = T.Compose([\n",
        "    horizontal_flip,\n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO)])\n",
        "\n",
        "train_dataset_with_augmentation = dataset.CcncsaDataset(\n",
        "    X_train, Y_train, image_transform_with_augmentation, target_transform_with_augmentation)\n",
        "    \n",
        "model = fast_scnn.FastSCNN(n_classes)\n",
        "\n",
        "cfg[\"transform\"] = \"horizontal_flip\"\n",
        "\n",
        "tune.run(partial(training_and_testing.train_model,\n",
        "                 device=device, model=model, dataset=train_dataset_with_augmentation, n_epochs=n_epochs,\n",
        "                 score_fn=score_fn, loss_fn=loss_fn, optimizer=optimizer, num_workers=(0, 0),\n",
        "                 evaluate=True, class_weights=class_weights),\n",
        "         config=cfg,\n",
        "         num_samples=num_samples,\n",
        "         resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
        "         progress_reporter=reporter,\n",
        "         checkpoint_at_end=True,\n",
        "         checkpoint_freq=1,\n",
        "         local_dir=local_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downloading updated training results if running on colab\n",
        "! if test $executing_on_colab = 'True' ; then zip -r $checkpoint_archive $checkpoint_path ; fi\n",
        "if executing_on_colab is True: files.download(checkpoint_archive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M0iJkKYbZpJG"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"trialProgress\">\n",
              "  <h3>Trial Progress</h3>\n",
              "  <table>\n",
              "<thead>\n",
              "<tr><th>Trial name             </th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th style=\"text-align: right;\">  experiment_tag</th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_score</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th><th style=\"text-align: right;\">  val_score</th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_model_99b0e_00000</td><td>2023-02-03_03-45-26</td><td>True  </td><td>                </td><td>04e97dcbfe7f4eeaa0ea3d64b5d4514b</td><td style=\"text-align: right;\">               0</td><td>lenovo-notebook</td><td style=\"text-align: right;\">                        10</td><td>127.0.0.1</td><td style=\"text-align: right;\">18976</td><td style=\"text-align: right;\">              2661.2</td><td style=\"text-align: right;\">           265.631</td><td style=\"text-align: right;\">        2661.2</td><td style=\"text-align: right;\"> 1675392326</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">    0.129888</td><td style=\"text-align: right;\">     0.615737</td><td style=\"text-align: right;\">                  10</td><td>99b0e_00000</td><td style=\"text-align: right;\">  0.142262</td><td style=\"text-align: right;\">   0.617483</td><td style=\"text-align: right;\">     0.015414</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>\n",
              "<style>\n",
              ".trialProgress {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".trialProgress h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".trialProgress td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-03 03:45:26,981\tINFO tune.py:762 -- Total run time: 2669.25 seconds (2668.97 seconds for the tuning loop).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Status ==\n",
            "Current time: 2023-02-03 03:45:26 (running for 00:44:28.98)\n",
            "Memory usage on this node: 6.1/7.4 GiB \n",
            "Using FIFO scheduling algorithm.\n",
            "Resources requested: 0/12 CPUs, 0/1 GPUs, 0.0/1.34 GiB heap, 0.0/0.67 GiB objects\n",
            "Result logdir: c:\\Data\\GitHub\\deep-seasonal-color-analysis-system\\models\\preprocessing\\FastSCNN\\train_model_2023-02-03_03-00-57\n",
            "Number of trials: 1/1 (1 TERMINATED)\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "| Trial name              | status     | loc             |   train_loss |   train_score |   val_loss |   val_score |   training_iteration |\n",
            "|-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------|\n",
            "| train_model_99b0e_00000 | TERMINATED | 127.0.0.1:18976 |     0.129888 |      0.615737 |   0.142262 |    0.617483 |                   10 |\n",
            "+-------------------------+------------+-----------------+--------------+---------------+------------+-------------+----------------------+\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x134125a9900>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === training with vaugmentation: center_crop ===\n",
        "\n",
        "image_transform_with_augmentation = T.Compose([\n",
        "    center_crop,\n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO), \n",
        "    custom_transforms.BilateralFilter(sigma_color, sigma_space, diameter), \n",
        "    T.Normalize(config.NORMALIZE_MEAN, config.NORMALIZE_STD)])\n",
        "\n",
        "target_transform_with_augmentation = T.Compose([\n",
        "    center_crop,\n",
        "    T.Resize(slurm_config.GLOBAL_INPUT_SIZE_TRAINING_DEMO)])\n",
        "\n",
        "train_dataset_with_augmentation = dataset.CcncsaDataset(\n",
        "    X_train, Y_train, image_transform_with_augmentation, target_transform_with_augmentation)\n",
        "\n",
        "model = fast_scnn.FastSCNN(n_classes)\n",
        "\n",
        "cfg[\"transform\"] = \"center_crop\"\n",
        "\n",
        "tune.run(partial(training_and_testing.train_model,\n",
        "                 device=device, model=model, dataset=train_dataset_with_augmentation, n_epochs=n_epochs,\n",
        "                 score_fn=score_fn, loss_fn=loss_fn, optimizer=optimizer, num_workers=(0, 0),\n",
        "                 evaluate=True, class_weights=class_weights),\n",
        "         config=cfg,\n",
        "         num_samples=num_samples,\n",
        "         resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
        "         progress_reporter=reporter,\n",
        "         checkpoint_at_end=True,\n",
        "         checkpoint_freq=1,\n",
        "         local_dir=local_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downloading updated training results if running on colab\n",
        "! if test $executing_on_colab = 'True' ; then zip -r $checkpoint_archive $checkpoint_path ; fi\n",
        "if executing_on_colab is True: files.download(checkpoint_archive)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "82f66c251be9d40cacb10d5ee31b9d775ddf82f4eb2e1565bb5820a0e364e9ae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
